# Video-Data-Preprocessing-and-YOLOv7-Model-Fine-Tuning

## **Project Overview:**
This repository contains the code and resources for preprocessing video data and fine-tuning a YOLO (You Only Look Once) object detection model. If you're looking to create a video object detection system, this project is your starting point. By following the steps provided in the notebooks, you'll be able to train a YOLOv7 model tailored to your specific video data, 

## **Key Features**
- **Data Preprocessing**: Efficiently preprocess video data to extract frames, annotations, and other relevant information.
- **Customization**: Fine-tune YOLOv7 models using your preprocessed data, allowing you to address specific use cases and adapt to unique challenges.
- **Interactive Notebooks**: Each step in the code is explained in detail using Jupyter notebooks, making it easy to understand and customize the process.


## **Notebooks**
- 01 data_preprocessing: everything regarding video data preprocessing from extracting video frames to saving the labels and video frames.
- 02 data_Augmentation: steps to perform data augmentation for frames (and labels in case of rotation) this step is taken to enhance the results of YOLOv7
- 03 model_finetuning: Code for fine-tuning YOLO model.

## **Integration with Bigger Project**

This video data preprocessing and YOLO model fine-tuning project was a crucial component of a larger project that involved implementing object detection on a website. 

check the video listed above to watch the demo of that project :star2:  :video_camera:


## **Acknowledgments**
I would like to acknowledge the YOLO project and the contributors to various open-source libraries and video dataset that made this project possible.
Also, huge cknowledgment and credit to the team members who worked on the Abnormal Behavior detection project


